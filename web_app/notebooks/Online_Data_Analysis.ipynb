{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import shapefile\n",
    "import pandas as pd\n",
    "import re\n",
    "from shapely import geometry\n",
    "import os\n",
    "import seaborn\n",
    "from collections import defaultdict\n",
    "from shapely import ops\n",
    "import pickle\n",
    "import matplotlib.pyplot  as plt\n",
    "from shapely import speedups\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from yelp.client import Client\n",
    "#from yelp.oauth1_authenticator import Oauth1Authenticator\n",
    "#from haversine import haversine\n",
    "import numpy as np\n",
    "import math\n",
    "import shapely\n",
    "import shapefile\n",
    "import os\n",
    "import scipy as sp\n",
    "import matplotlib as mpl \n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "import seaborn as sns\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Circle\n",
    "import glob\n",
    "import shapefile\n",
    "#import mpl_toolkits.basemap.pyproj as pyproj\n",
    "from sklearn import cluster\n",
    "from IPython import display\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import json\n",
    "import utm\n",
    "from collections import defaultdict\n",
    "from numpy import linalg\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speedups.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we will extract the necessary data from the shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self-intersection at or near point -74.039740173399863 40.699024314884056\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/logging/__init__.py\", line 874, in emit\n",
      "    stream.write(fs % msg)\n",
      "IOError: [Errno 5] Input/output error\n",
      "Logged from file geos.py, line 230\n"
     ]
    }
   ],
   "source": [
    "sf = shapefile.Reader(\"new-york_new-york.imposm-shapefiles/new-york_new-york_osm_admin.shp\")\n",
    "sf_ref = sf.shapeRecords()\n",
    "names = {\"Kings County\":\"Brooklyn\",\"Queens County\":\"Queens\",\"Richmond County\":\"Statten Island\",\n",
    "         \"New York County\":\"Manhattan\",\"Bronx County\":\"Bronx\"}\n",
    "ny_records = {}\n",
    "polygons = []\n",
    "for rec in sf_ref:\n",
    "    name = rec.record[2]\n",
    "    if rec.record[-1] == 6 and name in names:\n",
    "        poly = geometry.Polygon(rec.shape.points)\n",
    "        if not poly.is_valid:\n",
    "            poly = poly.buffer(0)[1]\n",
    "        ny_records[names[name]] = poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minLat = np.inf\n",
    "maxLat = -np.inf\n",
    "minLng = np.inf\n",
    "maxLng = -np.inf\n",
    "for bur in ny_records:\n",
    "    lng,lat = ny_records[bur].boundary.xy\n",
    "    lngMin,lngMax = min(lng),max(lng)\n",
    "    latMin,latMax = min(lat), max(lat)\n",
    "    if lngMin < minLng:\n",
    "        minLng = lngMin\n",
    "    if lngMax > maxLng:\n",
    "        maxLng = lngMax\n",
    "    if latMin < minLat:\n",
    "        minLat = latMin\n",
    "    if latMax > maxLat:\n",
    "        maxLat = latMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_grid(spacing):\n",
    "    latNums = int((maxLat-minLat)/spacing)\n",
    "    lngNums =int((maxLng-minLng)/spacing)\n",
    "    latAr = np.linspace(minLat-10**(-10),maxLat+10**(-10), latNums)\n",
    "    lngAr= np.linspace(minLng-10**(-10), maxLng+10**(-10),lngNums)\n",
    "    boxes = []\n",
    "    for i in range(len(lngAr)-1):\n",
    "        for j in range(len(latAr)-1):\n",
    "            boxes.append(geometry.box(lngAr[i],latAr[j],lngAr[i+1],latAr[j+1]))\n",
    "    return (np.array(boxes).reshape(len(lngAr)-1, len(latAr)-1),latAr,lngAr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_relevant(boxes):\n",
    "    relevant = []\n",
    "    full_NYC = ops.unary_union([ny_records[val] for val in ny_records])\n",
    "    for box in boxes.flatten():\n",
    "        if box.intersects(full_NYC):\n",
    "            keep = True\n",
    "            relevant.append(box.intersection(full_NYC))\n",
    "        else:\n",
    "            relevant.append(None)\n",
    "    return np.array(relevant).reshape(boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPACING = 0.005/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BOXES,latAr,lngAr = get_grid(SPACING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RELEVANT = get_relevant(BOXES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_index(lat,lng,latAr,lngAr):\n",
    "    jLat = np.argmax(lat <= latAr)-1\n",
    "    iLng = np.argmax(lng<=lngAr)-1\n",
    "    return (iLng,jLat)\n",
    "def get_burough(coord,records):\n",
    "    #lat_str = \"_latitude\"\n",
    "    #lng_str = \"_longitude\"\n",
    "    #NYC = get_NYC_records(sf)\n",
    "    #shapes = sf.shapes()\n",
    "    point = geometry.Point(coord[::-1])\n",
    "\n",
    "    for bur, poly in records.items():\n",
    "        #if poly[0].contains(point):\n",
    "        if poly.contains(point):\n",
    "            return bur\n",
    "    return None\n",
    "def get_all_burough(df, drop_or_pick = \"dropoff\"):\n",
    "    coords = df[[drop_or_pick + \"_lat\",drop_or_pick +\"_long\"]].values\n",
    "    return map(lambda x: get_burough(x,ny_records),coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_boxes(df,latAr,lngAr):\n",
    "    coord_pick = df[[\"pickup_lat\", \"pickup_long\"]].values\n",
    "    coord_drop = df[[\"dropoff_lat\", \"dropoff_long\"]].values\n",
    "    pick_vals = pd.DataFrame({\"pick_grid\":map(lambda x: get_index(*x,latAr = latAr,lngAr = lngAr), coord_pick)})\n",
    "    drop_vals = pd.DataFrame({\"drop_grid\":map(lambda x: get_index(*x,latAr = latAr,lngAr = lngAr), coord_drop)})\n",
    "    return pd.concat([pick_vals,drop_vals], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rest_boxes(df,latAr,lngAr):\n",
    "    coords = df[[\"Lat\",\"Long\"]].values\n",
    "    return pd.DataFrame({\"grid_point\":map(lambda x: get_index(*x,latAr = latAr,lngAr = lngAr), coords)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyc_centroid = {\"lat\":40.6639206199602,\"lng\": -73.9383529238219}\n",
    "bounds_of_nyc = {\"lat\":(minLat,maxLat), \"lng\":(minLng, maxLng)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_datetime(df):\n",
    "    cols = [\"pickup_datetime\",\"dropoff_datetime\"]\n",
    "    for col in cols:\n",
    "        df.loc[:,col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')\n",
    "def half_hour_grading(date_time):\n",
    "    time = date_time.time()\n",
    "    h,m = time.hour,time.minute\n",
    "    if m < 30:\n",
    "        m = 0\n",
    "    else:\n",
    "        m = 0.5\n",
    "    return h + m\n",
    "\n",
    "def add_details(df):\n",
    "    #df.loc[:,\"pickup_year\"] = df[\"pickup_datetime\"].apply(lambda x: x.year)\n",
    "    df.loc[:,\"pickup_month\"] = df[\"pickup_datetime\"].apply(lambda x: x.month)\n",
    "    df.loc[:,\"pickup_day\"] = df[\"pickup_datetime\"].apply(lambda x: x.weekday())\n",
    "    df.loc[:,\"duration\"] = df[\"dropoff_datetime\"]-df[\"pickup_datetime\"]\n",
    "    df.loc[:,\"time_category_pick\"] = df[\"pickup_datetime\"].apply(lambda x: x.hour)\n",
    "    df.loc[:,\"time_category_drop\"] = df[\"dropoff_datetime\"].apply(lambda x: x.hour)\n",
    "    df.loc[:,\"half_hour_pick\"] = df[\"pickup_datetime\"].apply(lambda x: half_hour_grading(x))\n",
    "    df.loc[:,\"half_hour_drop\"] = df[\"dropoff_datetime\"].apply(lambda x: half_hour_grading(x))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(df, bounds, remove_airport = True):\n",
    "    min_lat, max_lat = bounds[\"lat\"]\n",
    "    min_long, max_long = bounds[\"lng\"]\n",
    "    dfFilter = df[(min_lat <= df.pickup_lat) &(df.pickup_lat <= max_lat) & (min_long <= df.pickup_long) \\\n",
    "                  &(df.pickup_long<= max_long)]\n",
    "    dfFilter = dfFilter[(min_lat <= dfFilter.dropoff_lat) &(dfFilter.dropoff_lat <= max_lat) \\\n",
    "                       & (min_long <= dfFilter.dropoff_long)  &(dfFilter.dropoff_long<= max_long)]\n",
    "    dfFilter = dfFilter[dfFilter.duration >= datetime.timedelta(0)]\n",
    "    #if remove_airport:\n",
    "    #    dfFilter = dfFilter[dfFilter.rate_code.isin([1,5,6])]\n",
    "    return dfFilter.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coords(df):\n",
    "    pick_result = {}\n",
    "    drop_result = {}\n",
    "    for name,group in df:\n",
    "        pick_result[name] = zip(group.pickup_lat.values, group.pickup_long.values)\n",
    "        drop_result[name] = zip(group.dropoff_lat.values, group.dropoff_long.values)\n",
    "    return (pick_result, drop_result)\n",
    "def convert_to_xy_list(coord_list):\n",
    "    xy_list = map(lambda x: utm.from_latlon(*x), coord_list)\n",
    "    return xy_list\n",
    "def convert_to_xy(coord_dict):\n",
    "    return dict([(key,convert_to_xy_list(coord_dict[key]))for key in coord_dict])\n",
    "def strip_xy(coord_list):\n",
    "    return [val[:2] for val in coord_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dict(groups, coords):\n",
    "    res = defaultdict(list)\n",
    "    for group, coord in zip(groups, coords):\n",
    "        if group != -1:\n",
    "            res[group].append(utm.to_latlon(*coord))\n",
    "    return dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clusterCOORD(coordsXY,throttle = 0.01,metric =\"euclidean\"):\n",
    "    res = {}\n",
    "    #display.display(eps)\n",
    "    #display.display(min_samp)\n",
    "    for date in coordsXY:\n",
    "        if date[0] == \"Manhattan\":\n",
    "            eps = 50\n",
    "            min_samples = max(2,len(coordsXY[date])*throttle)\n",
    "        #display.display(date)\n",
    "        else:\n",
    "            eps = 500\n",
    "            min_samples = max(2,len(coordsXY[date])*throttle)\n",
    "        dbScan = cluster.DBSCAN(eps = eps, min_samples= min_samples, metric = metric)\n",
    "        result = dbScan.fit_predict(strip_xy(coordsXY[date]))\n",
    "        \n",
    "        res[date] = make_dict(result, coordsXY[date])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\"\n",
    "r = urllib.urlopen(url)\n",
    "soup = BeautifulSoup(r, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosen_names_2015 = [\"vendorID\", \"pickup_datetime\", \"dropoff_datetime\",\"passenger_count\", \"trip_distance\",\\\n",
    "                          \"pickup_long\",\"pickup_lat\",\"rate_code\",\"store_and_forward\",\"dropoff_long\",\"dropoff_lat\",\\\n",
    "                          \"payment_type\",\"fare_amount\",\"surcharge\",\"mta_tax\",\"tip_amount\",\"tolls_amount\",\\\n",
    "                          \"improvement_surcharge\",\"total_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_urls(soup):\n",
    "    for a in soup.findAll('a',href = True):\n",
    "        ref = a['href']\n",
    "        if \"tlc-trip-data\" in ref :\n",
    "            #test = urllib.URLopener()\n",
    "            #test.retrieve(ref, \"/Volumes/My Passport/Taxi_Data/Yellow_Taxi/yellow_tripdata_2014-01.csv\")\n",
    "            name = ref.split('/')[-1]\n",
    "            color = name.split('_')[0]\n",
    "            year = name.split(\"_\")[-1].split(\"-\")[0]\n",
    "            color = color[0].upper() + color[1:]+ \"_Taxi\"\n",
    "            #print name, color\n",
    "            file_path = color +\"/\" + name\n",
    "            if int(year) >=2015 and color == 'Yellow_Taxi':\n",
    "                yield (ref,name.split(\"-\")[-1][:2])\n",
    "def turn_into_panda(soup):\n",
    "    for url in get_urls(soup):\n",
    "        yield (pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reform_data_frame(soup):\n",
    "    for df in turn_into_panda(soup):\n",
    "        df.columns = chosen_names_2015\n",
    "        convert_datetime(df)\n",
    "        add_details(df)\n",
    "        df = clean_data(df, bounds_of_nyc)\n",
    "        yield df\n",
    "        #add_details\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_burough_info(df,soup,spacing):\n",
    "    #for df in reform_data_frame(soup):\n",
    "    gridVals = get_all_boxes(df,latAr,lngAr).reset_index(drop = True)\n",
    "    burVals = pd.Series(get_all_burough(df))\n",
    "    burVal = pd.DataFrame({\"bur\":burVals}).reset_index(drop = True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    gridVals = gridVals.reset_index(drop = True)\n",
    "\n",
    "    return pd.concat([df, burVals,gridVals], axis = 1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([             u'vendorID',       u'pickup_datetime',\n",
       "            u'dropoff_datetime',       u'passenger_count',\n",
       "               u'trip_distance',           u'pickup_long',\n",
       "                  u'pickup_lat',             u'rate_code',\n",
       "           u'store_and_forward',          u'dropoff_long',\n",
       "                 u'dropoff_lat',          u'payment_type',\n",
       "                 u'fare_amount',             u'surcharge',\n",
       "                     u'mta_tax',            u'tip_amount',\n",
       "                u'tolls_amount', u'improvement_surcharge',\n",
       "                u'total_amount',           u'pickup_year',\n",
       "                u'pickup_month',            u'pickup_day',\n",
       "                    u'duration',    u'time_category_pick',\n",
       "          u'time_category_drop',        u'half_hour_pick',\n",
       "              u'half_hour_drop',                        0,\n",
       "                   u'pick_grid',             u'drop_grid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = get_burough_info(df, soup,SPACING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"ti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 450 is out of bounds for axis 0 with size 446",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-29d713e43058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_heat_map_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tip_amount\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Jan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-b0b7e1029b51>\u001b[0m in \u001b[0;36mget_heat_map_params\u001b[1;34m(df, item, blur, name)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mMAX_VAL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_cmap_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".dill\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 450 is out of bounds for axis 0 with size 446"
     ]
    }
   ],
   "source": [
    "get_heat_map_params(df, \"tip_amount\",0.1,\"Jan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_heat_map_params(df,item, blur,name):\n",
    "    MAX_VAL = np.log(np.log(df.groupby(item).agg('size').max()+1)+1)+0.000001\n",
    "    counts = df.groupby(item).agg('size')\n",
    "    #maxVal = counts.max() + 0.000001\n",
    "    vals = np.zeros(shape = boxes.shape)\n",
    "    for i,val in enumerate(counts.index):\n",
    "        vals[val] = np.log(np.log(counts.values[i]+1)+1)/MAX_VAL\n",
    "    with open(name + \"_cmap_\"+str(item)+\".dill\",\"w\") as f:\n",
    "        dill.dump(gaussian_filter(vals,sigma=blur),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_step1_get_coords(df):\n",
    "    Grouped = df.groupby(by = [\"bur\",\"pickup_year\",\"pickup_month\",\"pickup_day\",\"time_category_drop\"])\n",
    "    pick_coords, drop_coords = get_coords(df)\n",
    "    coords_pick_xy = convert_to_xy(pick_coords)\n",
    "    coords_drop_xy = convert_to_xy(drop_coords)\n",
    "    return (coords_pick_xy,coords_drop_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfIter = reform_data_frame(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = dfIter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? n\n",
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "%reset pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
